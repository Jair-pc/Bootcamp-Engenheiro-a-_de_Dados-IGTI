# Módulo 4 - Pipelines de Dados

# Desafio Final

## Objetivos:

Pipelines de Dados

Capítulo 1 Visual geral do pipeline de ciência de dados

 1.1      Dados, fontes de dados, Big data e tipos de dados

1.2      O Pipeline de Ciência de dados

 

Capítulo 2 Extração de dados - ENADE - INEP - Ministério da Educação

2.1       Extração automatizada dos dados

2.2       Transformação de dados - Parte 1

2.3       Transformação de dados - Parte 2

 

Capítulo 3 Extração de dados - Prática - Twitter API

3.1       Configurando uma conta de DEV no Twtiter

3.2       Criando um app e pegando as chaves de acesso

3.3       Construindo um crawler para fazer streaming de tweets

 

Capítulo 4 Transformação de dados - Prática - Organização e Tratamento dos dados

4.1       Entendendo o formato do tweet - JSON

4.2       Limpeza e organização dos dados do Twitter - Parte 1

4.3       Limpeza e organização dos dados do Twitter - Parte 2

4.4       Ingestão de dados do Twitter em tabela relacional

 

Trabalho Prático 

 ✔ Extração de Dados;

 ✔ Desenvolvimento de crawlers;

 ✔ Transformações e análise de dados.


Capítulo 5 Soluções de ETL

5.1    Introdução às Soluções de ETL

5.2.    Pentaho

5.3.    Apache Nifi

5.4.    Apache Airflow

5.5.    KubeFlow

5.6.    Prefect

 

Capítulo 6 Data Flow na prática - AirFlow

6.1       Instalação do AirFlow

6.2       AirFlow rodando na nuvem

6.3       Tasks do AirFlow

6.4       Programando execuções do Pipeline

6.5       Condicionais

6.6       Paralelismos

6.7       Integrações para entrega

 

Capítulo 7 Data Flow na prática - Prefect

7.1       Configuração do ambiente Prefect na nuvem

7.2       Tasks do Prefect

7.3       Programando execuções e analisando o dashboard

7.4       Integrações para entrega

 

Capítulo 8 Pipelines de Dados near real time com Kafka

8.1       Resumo, outras ferramentas e próximos passos

  

Desafio 

 ✔ Desenvolvimento de crawlers;

 ✔ Pipeline de ETL;

 ✔  Orquestração e automatização de DataFlow;

 ✔ Análise Exploratória de Dados (EDA).
